{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code taken and adapted from TensorFlow Tutorials: Neural machine translation with attention\n",
        "\n",
        "https://www.tensorflow.org/text/tutorials/nmt_with_attention"
      ],
      "metadata": {
        "id": "7dfi5CZ72il-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPWYvh1C-QpA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMOzUqkeBlQM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ2xdjzyBrUc"
      },
      "outputs": [],
      "source": [
        "# Download the file\n",
        "import pathlib\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFBeQPP1BvHJ"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "  context = np.array([target for target, context in pairs])\n",
        "  target = np.array([context for target, context in pairs])\n",
        "\n",
        "  return target, context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOJ0REIdBz9S",
        "outputId": "6e2f1e32-a0d2-4b1f-8d10-03ccc487fa3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\n"
          ]
        }
      ],
      "source": [
        "spa_raw, eng_raw = load_data(path_to_file)\n",
        "print(eng_raw[-3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He1qzYDJB3vO",
        "outputId": "4c793b70-453e-47f0-d111-64caf3934c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático.\n"
          ]
        }
      ],
      "source": [
        "print(spa_raw[-3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7_INBkrB8DB"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(eng_raw)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "is_train = np.random.uniform(size=(len(spa_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((eng_raw[is_train], spa_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((eng_raw[~is_train], spa_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GTBrqw2CHYg",
        "outputId": "48509b19-f926-48b0-80ec-665b31d334ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'How was the Eve of New Year party?'\n",
            "b'How was the Eve of New Year party?'\n"
          ]
        }
      ],
      "source": [
        "example_text = tf.constant('How was the Eve of New Year party?')\n",
        "\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBN3ZIDXCIxV"
      },
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EweVUvXICI0L",
        "outputId": "60f91c69-6ca6-4b3a-af7a-e0f1ea181397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How was the Eve of New Year party?\n",
            "[START] how was the eve of new year party ? [END]\n"
          ]
        }
      ],
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyZo1KZKCI3C"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX-VBAtWCI55",
        "outputId": "2f5cf42b-6025-415e-8751-b66f163ce092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " '.',\n",
              " 'the',\n",
              " 'i',\n",
              " 'to',\n",
              " 'you',\n",
              " 'tom',\n",
              " 'a',\n",
              " '?',\n",
              " 'is',\n",
              " 'he',\n",
              " 'in',\n",
              " 'of',\n",
              " 'that',\n",
              " 'it',\n",
              " ',',\n",
              " 'was']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "context_text_processor.get_vocabulary()[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFNhdjklCUg4",
        "outputId": "1067bd6c-c2cc-44c9-ad80-3558a415a014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " '.',\n",
              " 'que',\n",
              " 'de',\n",
              " 'el',\n",
              " 'a',\n",
              " 'no',\n",
              " 'tom',\n",
              " 'la',\n",
              " '?',\n",
              " '¿',\n",
              " 'en',\n",
              " 'es',\n",
              " 'un',\n",
              " 'se',\n",
              " 'me',\n",
              " ',']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "target_text_processor.get_vocabulary()[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Edn6Y9rOCZ2R"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2c8bu09CgkR",
        "outputId": "867788be-8629-415c-da9c-ba25c6836e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2    8  108 1415 1735    1  620   69    8   28]\n",
            "\n",
            "[   2    9  180  521  531    1   45   76 2676    4]\n",
            "[   9  180  521  531    1   45   76 2676    4    3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba7fQXuDCjkr"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0NhJkcfClr2"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    #shape_checker = ShapeChecker()\n",
        "    #shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    #shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    #shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7_MozmrCpDM",
        "outputId": "513df59c-1ad8-4c51-e5f8-4ba65a44eb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (64, 16)\n",
            "Encoder output, shape (batch, s, units): (64, 16, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jeo2U3NQFAma"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    #shape_checker = ShapeChecker()\n",
        "\n",
        "    #shape_checker(x, 'batch t units')\n",
        "    #shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    #shape_checker(x, 'batch t units')\n",
        "    #shape_checker(attn_scores, 'batch heads t s')\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    #shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3n6ixelFM2y",
        "outputId": "e4a3ad28-4cb5-4616-acba-45afaf3652bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (64, 16, 256)\n",
            "Target sequence, shape (batch, t, units): (64, 14, 256)\n",
            "Attention result, shape (batch, t, units): (64, 14, 256)\n",
            "Attention weights, shape (batch, t, s):    (64, 14, 16)\n"
          ]
        }
      ],
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                  output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8zbxcdpFPjf",
        "outputId": "978b932f-5e06-484c-9d27-62be2dffe968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.        , 0.99999994, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuklvxPPFc8v"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou3u9c-rFfB0"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  \n",
        "  #shape_checker = ShapeChecker()\n",
        "  #shape_checker(x, 'batch t')\n",
        "  #shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  #shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  #shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  #shape_checker(x, 'batch t units')\n",
        "  #shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  #shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEpvSWEAFjAw"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRqnCkQ4FqcS",
        "outputId": "2c01330a-bb47-4272-90ad-2a346f5dfdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (64, 16, 256)\n",
            "input target tokens shape: (batch, t) (64, 14)\n",
            "logits shape shape: (batch, target_vocabulary_size) (64, 14, 5000)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6dNiVO9FvdH"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYml0165Fvf9"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D8KfaMUFvjn"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJBNZxZrF2T6"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "\n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNKPHjb6F8Me",
        "outputId": "41bd2848-6e0d-40f3-8e69-1ef4a92b88c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'aves bajando oro animal podrias entiendo exitoso pocos entra ganas',\n",
              "       b'presentes darte viene haberse similar prestamo coser maneras ayudaria decirlo',\n",
              "       b'buscado rendirse firme tema ipad panico postura fiable soportarlo medalla'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujSG5wK3F_M7"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-8dYvpsGBm5",
        "outputId": "d439ac32-cc26-47b6-96cf-fc9d3ab8d594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (64, 16)\n",
            "Target tokens, shape: (batch, t) (64, 14)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (64, 14, 5000)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3iFbQxJGEhi"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdvzaTFPGHJg"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xDsu4AFGI62"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VW3O_NgGLBL",
        "outputId": "6596a3ed-8185-4bd2-bfbd-daac2035d02d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 8.517193, 'expected_acc': 0.0002}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZziSrsKGNzj",
        "outputId": "64efb818-e56c-4696-945e-571c520e94b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 11s 22ms/step - loss: 8.5175 - masked_acc: 2.6525e-04 - masked_loss: 8.5175\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 8.517463684082031,\n",
              " 'masked_acc': 0.0002652520197443664,\n",
              " 'masked_loss': 8.517463684082031}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=50, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huiE8ToFGQTv",
        "outputId": "173697df-a236-4a33-d516-e1865df5f893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 33s 161ms/step - loss: 5.0469 - masked_acc: 0.2652 - masked_loss: 5.0469 - val_loss: 4.1248 - val_masked_acc: 0.3621 - val_masked_loss: 4.1248\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 3.7643 - masked_acc: 0.4028 - masked_loss: 3.7643 - val_loss: 3.4128 - val_masked_acc: 0.4431 - val_masked_loss: 3.4128\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 6s 55ms/step - loss: 3.1494 - masked_acc: 0.4744 - masked_loss: 3.1494 - val_loss: 2.9393 - val_masked_acc: 0.5001 - val_masked_loss: 2.9393\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 2.7433 - masked_acc: 0.5267 - masked_loss: 2.7433 - val_loss: 2.5394 - val_masked_acc: 0.5602 - val_masked_loss: 2.5394\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 6s 57ms/step - loss: 2.4288 - masked_acc: 0.5681 - masked_loss: 2.4288 - val_loss: 2.3827 - val_masked_acc: 0.5678 - val_masked_loss: 2.3827\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 2.2215 - masked_acc: 0.5943 - masked_loss: 2.2215 - val_loss: 2.0834 - val_masked_acc: 0.6129 - val_masked_loss: 2.0834\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 5s 51ms/step - loss: 2.0233 - masked_acc: 0.6208 - masked_loss: 2.0233 - val_loss: 1.9437 - val_masked_acc: 0.6295 - val_masked_loss: 1.9437\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 1.8957 - masked_acc: 0.6390 - masked_loss: 1.8957 - val_loss: 1.7973 - val_masked_acc: 0.6481 - val_masked_loss: 1.7973\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 5s 53ms/step - loss: 1.7835 - masked_acc: 0.6521 - masked_loss: 1.7835 - val_loss: 1.7718 - val_masked_acc: 0.6545 - val_masked_loss: 1.7718\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 5s 52ms/step - loss: 1.6831 - masked_acc: 0.6642 - masked_loss: 1.6831 - val_loss: 1.6648 - val_masked_acc: 0.6670 - val_masked_loss: 1.6648\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 1.6380 - masked_acc: 0.6699 - masked_loss: 1.6380 - val_loss: 1.4954 - val_masked_acc: 0.6908 - val_masked_loss: 1.4954\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 1.5671 - masked_acc: 0.6792 - masked_loss: 1.5671 - val_loss: 1.5029 - val_masked_acc: 0.6907 - val_masked_loss: 1.5029\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 5s 51ms/step - loss: 1.4848 - masked_acc: 0.6884 - masked_loss: 1.4848 - val_loss: 1.5040 - val_masked_acc: 0.6846 - val_masked_loss: 1.5040\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 1.4485 - masked_acc: 0.6969 - masked_loss: 1.4485 - val_loss: 1.4723 - val_masked_acc: 0.6866 - val_masked_loss: 1.4723\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 1.3999 - masked_acc: 0.7055 - masked_loss: 1.3938 - val_loss: 1.4190 - val_masked_acc: 0.6995 - val_masked_loss: 1.4190\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.2247 - masked_acc: 0.7294 - masked_loss: 1.2247 - val_loss: 1.3955 - val_masked_acc: 0.7045 - val_masked_loss: 1.3955\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 1.2054 - masked_acc: 0.7304 - masked_loss: 1.2054 - val_loss: 1.3858 - val_masked_acc: 0.7110 - val_masked_loss: 1.3858\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 1.2153 - masked_acc: 0.7280 - masked_loss: 1.2153 - val_loss: 1.4320 - val_masked_acc: 0.6972 - val_masked_loss: 1.4320\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 1.1936 - masked_acc: 0.7310 - masked_loss: 1.1936 - val_loss: 1.2987 - val_masked_acc: 0.7151 - val_masked_loss: 1.2987\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 1.2082 - masked_acc: 0.7291 - masked_loss: 1.2082 - val_loss: 1.3270 - val_masked_acc: 0.7178 - val_masked_loss: 1.3270\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 1.1834 - masked_acc: 0.7311 - masked_loss: 1.1834 - val_loss: 1.2757 - val_masked_acc: 0.7228 - val_masked_loss: 1.2757\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 1.1922 - masked_acc: 0.7331 - masked_loss: 1.1922 - val_loss: 1.3208 - val_masked_acc: 0.7150 - val_masked_loss: 1.3208\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 1.1771 - masked_acc: 0.7341 - masked_loss: 1.1771 - val_loss: 1.2814 - val_masked_acc: 0.7218 - val_masked_loss: 1.2814\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 1.1831 - masked_acc: 0.7322 - masked_loss: 1.1831 - val_loss: 1.2914 - val_masked_acc: 0.7151 - val_masked_loss: 1.2914\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=200,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 20,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IarisA5xIIOC"
      },
      "outputs": [],
      "source": [
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ytFnur83Gin4",
        "outputId": "207cc4a8-39b9-41e4-a078-504d55818cb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'¿ a [UNK] tambien va a ir tu dia ? '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "result = model.translate(['Hello how is going your day?'])\n",
        "result[0].numpy().decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRp50pgw7nSC"
      },
      "outputs": [],
      "source": [
        "class Export(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "  def translate(self, inputs):\n",
        "    return self.model.translate(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDUszfoA73yV"
      },
      "outputs": [],
      "source": [
        "export = Export(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HChQv63chr3"
      },
      "outputs": [],
      "source": [
        "inputs = [\n",
        "    'It is really cold here',\n",
        "    'This is my life.', \n",
        "    'His room is a mess.'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo7BYY7ycUJJ"
      },
      "outputs": [],
      "source": [
        "_ = export.translate(tf.constant(inputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bwToLvWccHk",
        "outputId": "0c9b3c4a-e008-4a26-912f-a52230971410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, cross_attention_5_layer_call_fn while saving (showing 5 of 32). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(export, 'translator',\n",
        "                    signatures={'serving_default': export.translate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqlyxUbGcrpT"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('translator')\n",
        "_ = reloaded.translate(tf.constant(inputs)) #warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqlYLCEGcuus",
        "outputId": "69bdc1d6-edf3-4796-e0f2-8a7eaf4ddfee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hace mucho frio aqui .                                             \n",
            "esta es mi vida .                                             \n",
            "su habitacion es un desastre .                                            \n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = reloaded.translate(tf.constant(inputs))\n",
        "\n",
        "print(result[0].numpy().decode())\n",
        "print(result[1].numpy().decode())\n",
        "print(result[2].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "HhCZCeih4cN-",
        "outputId": "3470c15b-f83b-47bb-e790-d750c4740a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff7ec9be6a0>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2y19N0Si18y"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from typing import List\n",
        "from loguru import logger\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.post(\"/translate/eng_to_spa\")\n",
        "async def create_items(text: List[str]):\n",
        "    logger.info(text)\n",
        "    result = reloaded.translate(tf.constant(text))\n",
        "    logger.info(result)\n",
        "    print(result)\n",
        "    return {\"result\": True, \"data\": result[0].numpy().decode()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J9tWJ1wi86D",
        "outputId": "094b982e-dcd5-4c21-b3b2-c38bfa7ec4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-04-17T02:28:14+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://67d8-35-231-6-15.ngrok.io\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [28045]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "\u001b[32m2023-04-17 02:29:54.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1m['Where are you from ?']\u001b[0m\n",
            "\u001b[32m2023-04-17 02:29:54.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mtf.Tensor([b'\\xc2\\xbf donde estan usted ?                                             '], shape=(1,), dtype=string)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'\\xc2\\xbf donde estan usted ?                                             '], shape=(1,), dtype=string)\n",
            "INFO:     54.86.50.139:0 - \"POST /translate/eng_to_spa HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-04-17 02:30:06.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1m['Hello Oscar']\u001b[0m\n",
            "\u001b[32m2023-04-17 02:30:06.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mtf.Tensor([b'[UNK] a [UNK] .                                              '], shape=(1,), dtype=string)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'[UNK] a [UNK] .                                              '], shape=(1,), dtype=string)\n",
            "INFO:     54.86.50.139:0 - \"POST /translate/eng_to_spa HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-04-17 02:30:13.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1m['Hi']\u001b[0m\n",
            "\u001b[32m2023-04-17 02:30:13.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mtf.Tensor([b'[UNK] de [UNK] ?                                              '], shape=(1,), dtype=string)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'[UNK] de [UNK] ?                                              '], shape=(1,), dtype=string)\n",
            "INFO:     54.86.50.139:0 - \"POST /translate/eng_to_spa HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-04-17 02:30:23.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1m['Tomorrow']\u001b[0m\n",
            "\u001b[32m2023-04-17 02:30:23.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_items\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mtf.Tensor([b'manana manana .                                               '], shape=(1,), dtype=string)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'manana manana .                                               '], shape=(1,), dtype=string)\n",
            "INFO:     54.86.50.139:0 - \"POST /translate/eng_to_spa HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [28045]\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}